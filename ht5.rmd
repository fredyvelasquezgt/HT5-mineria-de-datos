
---
title: "Informe HDT5"
author: "Fredy Velasquez, Angel Higueros, Pablo Escobar"
date: "19/3/2023"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Hoja de Trabajo 5: Naive Bayes

### 1. Use los mismos conjuntos de entrenamiento y prueba que utilizó en las dos hojas anteriores

```{r warning=FALSE, unload=TRUE}

#Librerias a utilizar
library(e1071)
library(caret)

#base de datos a utilzar
db<-read.csv('train.csv')

```


###  2. Elabore un modelo de regresión usando bayes ingenuo (naive bayes), el conjunto de entrenamiento y la variable respuesta SalesPrice. Prediga con el modelo y explique los resultados a los que llega. Asegúrese que los conjuntos de entrenamiento y prueba sean los mismos de las hojas anteriores para que los modelos sean comparables. 

```{r }
#Encontramos los percentiles
percentil <- quantile(db$SalePrice)
#Percentiles
estado<-c('Estado')
db$Estado<-estado
db <- within(db, Estado[SalePrice<=129975] <- 'Economica')

db$Estado[(db$SalePrice>129975 & db$SalePrice<=163000)] <- 'Intermedia'
db$Estado[db$SalePrice>163000] <- 'Cara'

#Bayes 
#Usamos el 70% de datos
porcentaje<-0.7
#El experimento debe ser repetible
set.seed(1234)

corte <- sample(nrow(db),nrow(db)*porcentaje)
#Entrenamiento
train<-db[corte,]
#Prueba
test<-db[-corte,]

```

### 3.Haga un modelo de clasificación, use la variable categórica que hizo con el precio de las casas (barata, media y cara) como variable respuesta. 


```{r warning=FALSE}
#Entrenar el modelo
modelo<-naiveBayes(train$Estado~., data=train)
#Casting de las variables, ya que el modelo pide datos numericos
test$GrLivArea<-as.numeric(test$GrLivArea)
test$YearBuilt<-as.numeric(test$YearBuilt)
test$BsmtUnfSF<-as.numeric(test$BsmtUnfSF)
test$TotalBsmtSF<-as.numeric(test$TotalBsmtSF)
test$GarageArea<-as.numeric(test$GarageArea)
test$YearRemodAdd<-as.numeric(test$YearRemodAdd)
test$SalePrice<-as.numeric(test$SalePrice)
test$LotArea<-as.numeric(test$LotArea)
#Realizamos la prediccion
predBayes<-predict(modelo, newdata = test[,c("GrLivArea","YearBuilt","BsmtUnfSF","TotalBsmtSF","GarageArea","YearRemodAdd", "SalePrice","LotArea")])
#Convertimos la prediccion a factor
predBayes<-as.factor(predBayes)
#Creamos la matriz de confusion
cm<-caret::confusionMatrix(as.factor(predBayes),as.factor(test$Estado))

```
## 4. Utilice los modelos con el conjunto de prueba y determine la eficiencia del algoritmo para predecir y clasificar. 


```{r}
table(predBayes)
table(test$Estado)

```

Tal como se observa en la prediccion obtuvimos **209** casas caras, **113** casas economica y **117** Intermedias.
Mientras que el valor del test es **222** casas caras, **106** casas economica y **111** Intermedias.
Demostrando que tuvimos una buena prediccion.

## 5 y 6. Analice los resultados del modelo de regresión. ¿Qué tan bien le fue prediciendo?. Compare los resultados con el modelo de regresión lineal y el árbol de regresión que hizo en las hojas pasadas. ¿Cuál funcionó mejor?

```{r}
cm

```

Por otro lado la matriz de confusion demuestra que en la variable Cara clasifico 204 casas caras, 1 economica y 4 intermedia.
La variable economica clasifico 2 casas caras, 100 economicas y 11 intermedias.
La variable intermedia clasifico 16 casas caras, 5 economicas y 96 intermedias.
Ademas se evidencia que nuestro modelo tuvo una precision de **91%** demostrando que fue una muy buena prediccion, ya que no existe overfitting, 


## 7. Haga un modelo usando validación cruzada, compare los resultados de este con los del modelo anterior. ¿Cuál funcionó mejor?

```{r include=FALSE}
ct<-trainControl(method = "cv",train[,c("GrLivArea","YearBuilt","BsmtUnfSF","TotalBsmtSF","GarageArea","YearRemodAdd", "SalePrice","LotArea")],number=10, verboseIter=T)
modeloCaret<-train(Estado~ .,data=train[,c("GrLivArea","YearBuilt","BsmtUnfSF","TotalBsmtSF","GarageArea","YearRemodAdd", "SalePrice","LotArea","Estado")],method="nb",trControl = ct)

prediccionCaret<-predict(modeloCaret,newdata = test[,c("GrLivArea","YearBuilt","BsmtUnfSF","TotalBsmtSF","GarageArea","YearRemodAdd", "SalePrice","LotArea")])

cva<-caret::confusionMatrix(prediccionCaret,as.factor(test$Estado))
```

```{r}

cva

````

Realmente, si comparamos con el modelo "normal", osea el de Bayes, tuvimos una cierta mejora. no una muy amplia pero en terminos generales es una buena mejora, dado que nuestra presicion fue de **93%**, mientras que en Bayes obtuvimos un **91%**, cosa que podemos comprobar si nos vamos a la tabla de clasificaciones creada por el modelo cruzado:

  1. Cara: 214 Cara, 1 Economica y 7 Intermedia.
  
  2. Economica: 3 Cara, 100 Economica y 7 Intermedia
  
  3. Intermedia: 5 Cara, 5 Economica y 97 Intermedia 

De nuevo, comparado con el metodo de Bayes, tuvimos un aumento en cuanto a casas Caras, Intermedias y Economicas 

## 8.Compare la eficiencia del algoritmo con el resultado obtenido con el árbol de decisión (el de clasificación) y el modelo de random forest que hizo en la hoja pasada. ¿Cuál es mejor para predecir? ¿Cuál se demoró más en procesar?

Realmente este metodo fue mas rapido y sencillo que el arbol de clasificacion, se obtuvieron resultados similares, sin embargo, este demostro mas confiabilidad, cabe mencionar que lo mas importante de este modelo es que no se obtuvo overfitting ni la primera vez, ni con la validacion cruzada. Ademas, el arbol de regresion se obtuvo resultados mas explicativos, pero mas costoso en terminos de tiempo y eficiencia, por ello, si lo que se desea es mejorar la eficiencia el metodo de naive Bayes es el mejor para ello. 
